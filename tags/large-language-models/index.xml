<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Large Language Models on Federico Torrielli - Blog</title><link>https://federicotorrielli.github.io/blog/tags/large-language-models/</link><description>Recent content in Large Language Models on Federico Torrielli - Blog</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Thu, 28 Aug 2025 14:54:04 +0200</lastBuildDate><atom:link href="https://federicotorrielli.github.io/blog/tags/large-language-models/index.xml" rel="self" type="application/rss+xml"/><item><title>Agi Is Not Coming</title><link>https://federicotorrielli.github.io/blog/posts/agi-is-not-coming/</link><pubDate>Thu, 28 Aug 2025 14:54:04 +0200</pubDate><guid>https://federicotorrielli.github.io/blog/posts/agi-is-not-coming/</guid><description>&lt;p&gt;&lt;img src="https://files.catbox.moe/lrr9nu.png" alt="AGI is not coming"&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;What is AGI, and is it really around the corner?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We observe systems that demonstrate superhuman aptitude in narrow domains, yet fail at tasks requiring what seems to be trivial common sense or memory. One popular framing suggests the path to AGI is blocked not by a need for more scale, but by a set of &amp;ldquo;engineering problems&amp;rdquo;: we lack persistent memory, robust agentic scaffolding, and effective long-term planning frameworks. The underlying assumption is that the core intelligence, the Large Language Model, is a sufficiently powerful cognitive engine, and we must now simply build the correct chassis around it.&lt;/p&gt;</description></item></channel></rss>